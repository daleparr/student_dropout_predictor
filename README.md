# student_dropout_predictor
# **Student Dropout Predictor Using Decision Trees &amp; Deep Learning**

**Author:** Dale Parr  
**Date:** February 2025  

## **Table of Contents**
1. [Introduction](#introduction)  
2. [Data Overview](#data-overview)  
3. [Challenges in Data Preprocessing](#challenges-in-data-preprocessing)  
4. [Methodology](#methodology)  
5. [Model Performance and Results](#model-performance-and-results)  
6. [Business Insights and Recommendations](#business-insights-and-recommendations)  
7. [Conclusion](#conclusion)  
8. [Appendix](#appendix)  

---

## **üìå Introduction**
Student retention is critical for educational institutions, impacting **financial stability, academic success, and institutional reputation**. This study explores **machine learning techniques** to predict student dropout rates across **three data stages**:
- **Stage 1:** Applicant and course information  
- **Stage 2:** Student engagement data  
- **Stage 3:** Academic performance records  

### **üéØ Research Question**
> At what stage can student dropout be most accurately predicted, and which model performs best?

---

## **üìä Data Overview**
The dataset consists of **demographic, academic, and engagement-related features** collected across three stages.  
- **Target Variable:** `CompletedCourse` (1 = completion, 0 = dropout)  
- **Preprocessing Steps:**  
  - **Feature Selection:** Removed high-cardinality and irrelevant attributes.  
  - **Handling Missing Data:** Applied a **2% threshold** for removal and imputation strategies.  
  - **Encoding:** **Ordinal encoding** for ordered categories (e.g., education level), **one-hot encoding** for nominal variables.  
  - **Scaling:** Standardization for normally distributed features, min-max scaling for skewed features.  

These steps ensured **data quality, reduced noise**, and improved model performance.

---

## **‚ö†Ô∏è Challenges in Data Preprocessing**
### **1Ô∏è‚É£ Data Quality Issues**
- **Inconsistent formatting, missing values, and high-cardinality categorical features** required extensive cleaning.
  
### **2Ô∏è‚É£ Class Imbalance**
- **Dropouts were significantly fewer than course completers**, causing biased predictions.
- **Solution:** Applied **class weighting & SMOTE (oversampling)** to improve dropout detection.

### **3Ô∏è‚É£ Feature Engineering Complexity**
- Early-stage models lacked **engagement and academic performance features**, reducing predictive power.
- **Stage 3 data** provided **richer features**, significantly improving model performance.

### **4Ô∏è‚É£ Baseline Model Limitations**
- **XGBoost handled imbalanced data well** but required tuning.
- **Neural Networks suffered from overfitting** in early configurations.
- **Regularization techniques (Dropout, L2) improved generalization.**

---

## **üî¨ Methodology**
We tested two machine learning models:

### **‚úÖ XGBoost (Gradient-Boosted Decision Trees)**
- **Advantages:** Handles missing data, works well with imbalanced datasets.
- **Hyperparameters tuned using Grid Search:**
  - Learning rate
  - Maximum tree depth
  - Number of estimators  
- **Regularization Techniques:** L2 (`lambda` tuning) to prevent overfitting.

### **‚úÖ Neural Networks (Deep Learning)**
- **Advantages:** Detects complex relationships in high-dimensional data.
- **Tuning parameters:**
  - **Layer depth & neuron count**
  - **Dropout rate & batch size**
  - **L2 regularization for weight decay**
- **Early Stopping & Weight Curves** helped prevent overfitting.

### **üõ†Ô∏è Evaluation Metrics**
- **Accuracy** (Overall correctness)  
- **AUC-ROC** (Model‚Äôs ability to distinguish between classes)  
- **Precision & Recall** (False positive and false negative sensitivity)  
- **Confusion Matrix Analysis**  

Models were trained using **80-20 stratified train-test split**.

---

## **üìà Model Performance and Results**
### **Stage 2 Models**
```plaintext
| Model                                      | Accuracy | AUC   | Precision (Class 0) | Recall (Class 0) | F1-Score (Class 0) | Precision (Class 1) | Recall (Class 1) | F1-Score (Class 1) | Validation Loss Trend | Overfitting Risk |
|--------------------------------------------|----------|-------|----------------------|------------------|------------------|----------------------|------------------|------------------|----------------------|------------------|
| XGBoost Baseline                           | 0.9044   | 0.7648| 0.72                 | 0.57             | 0.63             | 0.93                 | 0.96             | 0.95             | Stable               | Moderate         |
| XGBoost Optimized                          | 0.9902   | 0.9762| 0.98                 | 0.96             | 0.97             | 0.99                 | 1.00             | 0.99             | Stable               | Low              |
```
‚úÖ **Best Model:** **XGBoost Optimized** (Highest Accuracy & Stability)

---
### **Stage 3 Model Performance**

```plaintext
| Model                                      | Accuracy | AUC   | Precision (Class 0) | Recall (Class 0) | F1-Score (Class 0) | Precision (Class 1) | Recall (Class 1) | F1-Score (Class 1) | Validation Loss Trend | Overfitting Risk |
|--------------------------------------------|----------|-------|----------------------|------------------|------------------|----------------------|------------------|------------------|----------------------|------------------|
| Baseline NN (Stage 3)                      | 0.9830   | 0.9971| 0.95                 | 0.93             | 0.94             | 0.99                 | 0.99             | 0.99             | Slightly Increasing  | Moderate         |
| NN (L2 Regularization & LR Tuning)         | 0.9759   | 0.9931| 0.94                 | 0.90             | 0.92             | 0.98                 | 0.99             | 0.99             | Stable               | Low              |
| XGBoost Baseline                           | 0.9906   | 0.9990| 0.97                 | 0.96             | 0.97             | 0.99                 | 1.00             | 0.99             | Stable               | Very Low         |
| XGBoost (With Lambda Regularization)       | 0.9902   | 0.9992| 0.98                 | 0.96             | 0.97             | 0.99                 | 1.00             | 0.99             | Stable               | Very Low         |
| XGBoost (With Deeper Lambda Regularization)| 0.9906   | 0.9992| 0.98                 | 0.96             | 0.97             | 0.99                 | 1.00             | 0.99             | Stable               | Very Low         |
| XGBoost (With Lambda & Dropout)            | 0.9914   | 0.9992| 0.98                 | 0.96             | 0.97             | 0.99                 | 1.00             | 0.99             | Stable               | Very Low         |
```

‚úÖ **Best Model:** **XGBoost (With Lambda & Dropout)** (Highest Accuracy & AUC)

---

## **üèÜ Business Insights and Recommendations**
### **1Ô∏è‚É£ Early Intervention Strategies**
- Implement **real-time academic monitoring dashboards**.
- Trigger **automated early alerts** for at-risk students.

### **2Ô∏è‚É£ Targeted Resource Allocation**
- Assign **mentorship & tutoring support** to flagged students.
- Develop **personalized learning plans**.

### **3Ô∏è‚É£ Model Deployment for Continuous Learning**
- **Integrate XGBoost into student management systems**.
- Create a **feedback loop** for continuous model improvement.

---

## **üîÆ Conclusion**
This study demonstrated that **machine learning can accurately predict student dropout**.  

‚úÖ **XGBoost consistently outperformed Neural Networks**, particularly in recall, computational efficiency, and stability.  
‚úÖ **Stage 3 features (academic performance data) were the strongest predictors**, making this phase ideal for interventions.  
‚úÖ **For deployment**, XGBoost is **the best model** due to its **high recall, interpretability, and low overfitting risk**.  

### **Future Work**
- **Test alternative ensemble models** (e.g., LightGBM, CatBoost).  
- **Incorporate behavioral data** (e.g., LMS engagement, discussion forum activity).  
- **Develop a hybrid approach** combining XGBoost's interpretability with NN's deep feature extraction.  

---

## **üìÅ Appendix**
- **Feature Importance Analysis** (Stage 2 & Stage 3)  
- **XGBoost Hyperparameter Tuning Summary**  
- **NN Training Curves & Overfitting Adjustments**  

üöÄ *This study demonstrates expert-level data science principles in predictive modeling and real-world deployment.* üöÄ
